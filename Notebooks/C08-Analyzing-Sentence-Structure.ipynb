{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "DataAnalysis"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from tools import show_subtitle"
   ]
  },
  {
   "source": [
    "# Ch8 分析句子结构\n",
    "\n",
    "前面的章节重点关注词的处理：识别、分析结构、分配词汇类别、获取词汇的含义、识别词序列或者n-grams的模式\n",
    "\n",
    "本章的学习目标：\n",
    "\n",
    "1.  使用形式化语法来描述无限的句子集合的结构\n",
    "2.  使用句法树来表示句子结构\n",
    "3.  使用解析器来分析句子，并且自动构建语法树\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 8.1 一些语法困境"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 8.1.1 语言数据和无限的可能性\n",
    "\n",
    "本章中将采用“生成文法”的形式化框架，其中一种“语言”被认为仅仅是所有合乎文法的句子的大集合，而文法只是一个形式化符号，可以用于“生成”这个集合的成员。\n",
    "\n",
    "文法的目的是给出一个明确的语言描述，使用 `S → S and S` 形式的递归产生式"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 8.1.2 普遍存在的歧义"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "groucho_grammar = nltk.CFG.fromstring('''\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | \"I\"\n",
    "VP -> V NP | VP PP\n",
    "Det -> \"an\" | \"my\"\n",
    "N -> \"elephant\" | \"pajamas\"\n",
    "V -> \"shot\"\n",
    "P -> \"in\"\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------- >第 1 个结构< ---------------\n(S\n  (NP I)\n  (VP\n    (VP (V shot) (NP (Det an) (N elephant)))\n    (PP (P in) (NP (Det my) (N pajamas)))))\n--------------- >第 2 个结构< ---------------\n(S\n  (NP I)\n  (VP\n    (V shot)\n    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "# 基于一种文法解析句子，可能会解析出两种结构\n",
    "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "parser = nltk.ChartParser(groucho_grammar)  # 图解析\n",
    "for i, tree in enumerate(parser.parse(sent)):\n",
    "    show_subtitle(f\"第 {i+1} 个结构\")\n",
    "    print(tree)"
   ]
  },
  {
   "source": [
    "## 8.2 文法的用途"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 8.2.1 超越 n-grams\n",
    "\n",
    "-   成分结构：是词与词结合在一起组成的单元。\n",
    "-   词汇的可替代性：在符合语法规则的句子中，长的词序列可以被一个更短的词序列替代，并且替代后不会导致句子不合语法规则\n",
    "    -   形成单元的每个序列都可以被单独的词替换。\n",
    "    -   短语的方法类别标签\n",
    "        -   名词短语（NP）\n",
    "        -   动词短语（VP）\n",
    "        -   介词短语（PP）\n",
    "\n",
    "句子长度是任意的，因此短语结构树的深度也是任意的。因为Sec7.4只能产生有限深度的结构，所以分块方法并不适合用于句法分析。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 8.3 上下文无关文法（context-free grammars，CFG）"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 8.3.1 一种简单的文法"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex8-1 一个简单的上下文无关文法的例子\n",
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP | V NP PP\n",
    "PP -> P NP\n",
    "V -> \"saw\" | \"ate\" | \"walked\"\n",
    "NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "Det -> \"a\" | \"an\" | \"the\" | \"my\" | \"The\"\n",
    "N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------- >第 1 个结构< ---------------\n(S\n  (NP (Det The) (N dog))\n  (VP\n    (V saw)\n    (NP (Det a) (N man) (PP (P in) (NP (Det the) (N park))))))\n--------------- >第 2 个结构< ---------------\n(S\n  (NP (Det The) (N dog))\n  (VP\n    (V saw)\n    (NP (Det a) (N man))\n    (PP (P in) (NP (Det the) (N park)))))\n"
     ]
    }
   ],
   "source": [
    "# 句子剖析会出现两个符合文法规则的结果，称为结构上有歧义。这个歧义称为介词短语附着歧义。\n",
    "sent = 'The dog saw a man in the park'.split()\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar1)  # 递归下降解析器 RecursiveDescentParser()\n",
    "for i, tree in enumerate(rd_parser.parse(sent)):\n",
    "    show_subtitle(f\"第 {i + 1} 个结构\")\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.app.rdparser()  # 通过这个演示可以辅助理解从顶向下的回溯策略的句法剖析过程"
   ]
  },
  {
   "source": [
    "### 8.3.2 编写自己的文法"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------- >第 1 个结构< ---------------\n(S (NP Mary) (VP (V saw) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "# 在文本文件创建和编辑语法会更加文法，然后可以利用函数加载到NLTK中进行解析\n",
    "grammar1 = nltk.data.load('mygrammar.cfg')\n",
    "sent = \"Mary saw Bob\".split()\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar1)  # trace = 2 不知道有何作用\n",
    "for i, tree in enumerate(rd_parser.parse(sent)):\n",
    "    show_subtitle(f\"第 {i + 1} 个结构\")\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "S -> NP VP\nVP -> V NP\nVP -> V NP PP\nPP -> P NP\nV -> 'saw'\nV -> 'ate'\nV -> 'walked'\nNP -> 'John'\nNP -> 'Mary'\nNP -> 'Bob'\nNP -> Det N\nNP -> Det N PP\nDet -> 'a'\nDet -> 'an'\nDet -> 'the'\nDet -> 'my'\nDet -> 'The'\nN -> 'man'\nN -> 'dog'\nN -> 'cat'\nN -> 'telescope'\nN -> 'park'\nP -> 'in'\nP -> 'on'\nP -> 'by'\nP -> 'with'\n"
     ]
    }
   ],
   "source": [
    "# 输出文法文件中的内容\n",
    "for p in grammar1.productions():\n",
    "    print(p)"
   ]
  },
  {
   "source": [
    "### 8.3.3 句法结构中的递归\n",
    "\n",
    "RecursiveDescentParser()无法处理形如X→XY的左递归产生式"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex-2：递归的上下文无关文法\n",
    "grammar2 = nltk.CFG.fromstring(\"\"\"\n",
    "S  -> NP VP\n",
    "NP -> Det Nom | PropN\n",
    "Nom -> Adj Nom | N\n",
    "VP -> V Adj | V NP | V S | V NP PP\n",
    "PP -> P NP\n",
    "PropN -> 'Buster' | 'Chatterer' | 'Joe'\n",
    "Det -> 'the' | 'a'\n",
    "N -> 'bear' | 'squirrel' | 'tree' | 'fish' | 'log'\n",
    "Adj  -> 'angry' | 'frightened' |  'little' | 'tall'\n",
    "V ->  'chased'  | 'saw' | 'said' | 'thought' | 'was' | 'put'\n",
    "P -> 'on'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------- >第 1 个结构< ---------------\n(S\n  (NP (Det the) (Nom (Adj angry) (Nom (N bear))))\n  (VP\n    (V chased)\n    (NP\n      (Det the)\n      (Nom (Adj frightened) (Nom (Adj little) (Nom (N squirrel)))))))\n"
     ]
    }
   ],
   "source": [
    "sent = 'the angry bear chased the frightened little squirrel'.split()\n",
    "# RecursiveDescentParser()无法处理形如X→XY的左递归产生式\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar2)\n",
    "for i, tree in enumerate(rd_parser.parse(sent)):\n",
    "    show_subtitle(f\"第 {i + 1} 个结构\")\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------- >第 1 个结构< ---------------\n(S\n  (NP (PropN Chatterer))\n  (VP\n    (V said)\n    (S\n      (NP (PropN Buster))\n      (VP\n        (V thought)\n        (S (NP (Det the) (Nom (N tree))) (VP (V was) (Adj tall)))))))\n"
     ]
    }
   ],
   "source": [
    "sent = 'Chatterer said Buster thought the tree was tall'.split()\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar2)\n",
    "for i, tree in enumerate(rd_parser.parse(sent)):\n",
    "    show_subtitle(f\"第 {i + 1} 个结构\")\n",
    "    print(tree)"
   ]
  },
  {
   "source": [
    "## 8.4 上下文无关文法分析\n",
    "\n",
    "解析器根据文法产生式处理输入的句子，并且建立一个或者多个符合文法的组成结构\n",
    "\n",
    "文法是一个格式良好的声明规则——实际上只是一个字符串，而不是程序。\n",
    "\n",
    "解析器是文法的解释程序，用于搜索所有的符合文法的树的空间，并且找出一棵与句子匹配的语法树\n",
    "\n",
    "两种分析算法：\n",
    "\n",
    "1.  自顶向下的递归下降分析，主要缺点：\n",
    "    -   左递归产生式，如：NP→NP PP，会进入死循环\n",
    "    -   解析器在处理不符合输入句子的词和结构时会浪费许多时间\n",
    "    -   回溯过程中可能会丢弃分析过的成分，需要再次重建\n",
    "2.  自底向上的移进归约分析，只建立与输入中的词对应的结构，对于每个子结构只建立一次\n",
    "    -   反复将下一个输入词捡到堆栈，叫做移位操作\n",
    "    -   替换前n项为一项的操作，叫做归约操作\n",
    "\n",
    "「移进——归约」解析器 ShiftReduceParser()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP | V NP PP\n",
    "PP -> P NP\n",
    "V -> \"saw\" | \"ate\" | \"walked\"\n",
    "NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "Det -> \"a\" | \"an\" | \"the\" | \"my\" | \"The\"\n",
    "N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------- >第 1 个结构< ---------------\n(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"
     ]
    }
   ],
   "source": [
    "sent = 'Mary saw a dog'.split()\n",
    "sr_parser = nltk.ShiftReduceParser(grammar1)\n",
    "for i, tree in enumerate(sr_parser.parse(sent)):\n",
    "    show_subtitle(f\"第 {i + 1} 个结构\")\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parsing 'Mary saw a dog'\n    [ * Mary saw a dog]\n  S [ 'Mary' * saw a dog]\n  R [ NP * saw a dog]\n  S [ NP 'saw' * a dog]\n  R [ NP V * a dog]\n  S [ NP V 'a' * dog]\n  R [ NP V Det * dog]\n  S [ NP V Det 'dog' * ]\n  R [ NP V Det N * ]\n  R [ NP V NP * ]\n  R [ NP VP * ]\n  R [ S * ]\n--------------- >第 1 个结构< ---------------\n(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"
     ]
    }
   ],
   "source": [
    "# 跟踪解析的过程\n",
    "sent = 'Mary saw a dog'.split()\n",
    "sr_parser = nltk.ShiftReduceParser(grammar1,trace = 2)\n",
    "for i, tree in enumerate(sr_parser.parse(sent)):\n",
    "    show_subtitle(f\"第 {i + 1} 个结构\")\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Warning: VP -> V NP PP will never be used\n"
     ]
    }
   ],
   "source": [
    "nltk.app.srparser()  # 通过这个演示可以辅助理解自底向上的称进归约的句法剖析过程"
   ]
  },
  {
   "source": [
    "### 8.4.3 左角落解析器\n",
    "\n",
    "是 自顶向下 和 自底向上 方法的混合体，是一个带有自底向上过滤的自顶向下的解析器\n",
    "\n",
    "左角落解析器，不会陷入左递归产生式死循环。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 8.4.4 符合语句规则的子串表（WFST）\n",
    "\n",
    "上述简单的解析器都存在完整性和效率问题，下面将基于图表分析：即利用动态规划算法来解决这些问题\n",
    "\n",
    "动态规划算法存储中间结果，并且在适当的时候重用，从而显著提高了效率。\n",
    "\n",
    "WFST的缺点：\n",
    "-   WFST本身不是一个分析树\n",
    "-   每个非词汇文法生产式都必须是二元的\n",
    "-   作为一个自下而上的文法，潜在地存在着浪费，因为它会在不符合文法的地方提出成分，后面又会放弃掉错误的成分\n",
    "-   WFST并不能表示句子中的结构歧义（如两个动词短语的读取）\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "N -> 'elephant'\nN\n('elephant',)\n"
     ]
    }
   ],
   "source": [
    "# 可以在文法中直接查找文本中单词所属类别\n",
    "# lhs : left-hand-side; rhs : right-hand-side\n",
    "text = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "productions = groucho_grammar.productions(rhs=text[3])\n",
    "for product in productions:\n",
    "    print(product)\n",
    "    print(product.lhs())\n",
    "    print(product.rhs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}